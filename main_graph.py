import os
import operator
from typing import Annotated, List, Tuple, TypedDict, Union
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate
from utils.logger_util import logger
from langgraph.graph import END, StateGraph, START
from pydantic import BaseModel, Field

load_dotenv()
llm = ChatOpenAI(
    model="deepseek-chat",
    api_key=os.getenv('DEEPSEEK_API_KEY'),
    base_url=os.getenv('DEEPSEEK_BASE_URL'),
    temperature=0.7,
    streaming=True  # å¼€å¯æµå¼
)

class PlanExecuteState(TypedDict):
    """å®šä¹‰çŠ¶æ€"""
    question: str # ç”¨æˆ·é—®é¢˜
    plan: List[str] # å¾…æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨
    past_steps: Annotated[List[Tuple], operator.add] # å·²å®Œæˆçš„æ­¥éª¤ï¼ˆæ­¥éª¤åï¼Œç»“æœï¼‰
    response: str # æœ€ç»ˆå›å¤

class Plan(BaseModel):
    """(ç»“æ„åŒ–è¾“å‡º) è§„åˆ’åˆ—è¡¨"""
    steps: List[str] = Field(description="ä¸€ç³»åˆ—å…·ä½“çš„æ­¥éª¤ï¼Œä¾‹å¦‚æŸ¥è¯¢å¤©æ°”ï¼ŒæŸ¥è¯¢æ™¯ç‚¹ç­‰") # è®¡åˆ’åˆ—è¡¨ç»“æ„

class Response(BaseModel):
    """ï¼ˆç»“æ„åŒ–è¾“å‡ºï¼‰é‡æ–°è§„åˆ’æˆ–ç»“æŸ"""
    response: str = Field(description="æœ€ç»ˆå›ç­”ï¼Œå¦‚æœè¿˜éœ€è¦ç»§ç»­æ‰§è¡Œæ­¥éª¤ï¼Œåˆ™ä¸ºç©ºå­—ç¬¦ä¸²")
    next_plan: List[str] = Field(description="å‰©ä½™æœªå®Œæˆçš„æ­¥éª¤åˆ—è¡¨")

def planner_node(state: PlanExecuteState):
    """æ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼Œç”Ÿæˆåˆå§‹è®¡åˆ’"""
    logger.info("ğŸš€è§„åˆ’å¸ˆæ­£åœ¨è§„åˆ’ä»»åŠ¡")
    question = state["question"]
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªæ—…æ¸¸è§„åˆ’ä¸“å®¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œåˆ¶å®šä¸€ä¸ªæ¸…æ™°çš„åˆ†å¸ƒæ‰§è¡Œè®¡åˆ’ã€‚"
    user_prompt = f"ç”¨æˆ·éœ€æ±‚ï¼š{question}"
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    # è°ƒç”¨æ¨¡å‹ï¼Œè·å–ç»“æ„åŒ–è¾“å‡º
    structured_llm  = llm.with_structured_output(Plan)
    response = structured_llm.invoke(messages)
    return {"plan": response.steps}

